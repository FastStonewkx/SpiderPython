# 爬虫的基本原理

## 爬虫概述

### 1. 获取网页
爬虫首先做的工作就是获取网页内容，就是获取网页的源代码。

1.向网站发送一个请求，返回的响应体便是网页源代码。
2.源代码报害了网页的部分有用信息，然后提取它们。
python提供了许多库，实现以上功能

### 2. 获取信息
获取源代码后解析这部分。（比如正则表达式）
根据网页源代码的特性解析，使得杂乱的数据变得条理清晰，以便后续的处理和分析。

### 3. 保存数据
保存数据到文本文件或者数据库中。

###  4. 自动化程序
爬虫就是通过程序提前设定好的步骤（123）自动化处理这些数据。

## 处理那些数据

- 最常抓取的就是HTML源码
- JSON字符串
- 二进制数据，如图片，视频，音频等
- 各种拓展名的文件，CSS，JavaScript和配置文件等。

总而言之，以上内容对应各自URL，基于HTTP或者HTTPS协议的，爬虫都可以抓取

## Javascript渲染页面

有时候通过工具抓取的源代码和浏览器中看到的不同/
因为页面越来越多的使用ajax、前端模块化工具构建，整个页面可能都是由JavaScript渲染的，也就是说原始页面就是一个空壳。

对于这种问题，可以分析后台ajax接口，使用python（Selenium、Splash等）这样的库来模拟实现Javascript渲染）。

